{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "import Graph_EEGresnet\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Code for Training Our model\n",
    "\n",
    "* This example is made based on subject-dependent paradigm in Physionet dataset.\n",
    "* The data should be organized as (num, eletrodes, data, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('data/Physionet.npy', allow_pickle=True).item()\n",
    "\n",
    "### The dataset and split code should be replaced for different dataset\n",
    "\n",
    "def split_data(fold, dataset):\n",
    "    X = [dataset[i]['X'] for i in dataset.keys() if i not in [87, 88, 91, 99, 103]]\n",
    "    y = [dataset[i]['y'] for i in dataset.keys() if i not in [87, 88, 91, 99, 103]]\n",
    "    X = np.concatenate(X)\n",
    "    y = np.concatenate(y)\n",
    "\n",
    "    n = 0\n",
    "    kf = KFold(n_splits=5, random_state=2022, shuffle=True)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        if n == fold:\n",
    "            X_train, y_train = X[train_index], y[train_index]\n",
    "            X_test, y_test = X[test_index], y[test_index]\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=2022)\n",
    "            break\n",
    "        n = n + 1\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'Ours_test'\n",
    "for fold in range(5):\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(fold, dataset)\n",
    "    model = Graph_EEGresnet.irfanet(960, 64, 128, 4, '', 0.075)\n",
    "    ## Graph_EEGresnet.irfanet(num_of_time_samples, num_of_eletrodes, filter_len, num_of_classes)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss={'convloss':Graph_EEGresnet.mycrossentropy_wrapper(0.075), 'graph_loss':Graph_EEGresnet.mycrossentropy_wrapper(0.075), 'fused_loss':Graph_EEGresnet.mycrossentropy_wrapper(0.075)}, \n",
    "                    loss_weights = {'convloss':1, 'graph_loss':1, 'fused_loss': 3}, metrics={'convloss':'accuracy', 'graph_loss': 'accuracy', 'fused_loss': 'accuracy'})\n",
    "\n",
    "    if not os.path.exists('model/%s'%MODEL_NAME):\n",
    "        os.mkdir('model/%s'%MODEL_NAME)\n",
    "    if not os.path.exists('model/%s/%s'%(MODEL_NAME, str(fold))):\n",
    "        os.mkdir('model/%s/%s'%(MODEL_NAME, str(fold)))\n",
    "    filepath='model/%s/%s'%(MODEL_NAME, str(fold))+\"/weights.hdf5\"\n",
    "\n",
    "    checkpoint = \\\n",
    "        ModelCheckpoint(filepath, monitor='val_fused_loss_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', overwrite=True, period=1)\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "        batch_size=32,\n",
    "        epochs=200,\n",
    "        validation_data=(X_val, y_val),\n",
    "        shuffle=True, verbose=1, callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-TF25GPU",
   "language": "python",
   "name": "my-tf25gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
